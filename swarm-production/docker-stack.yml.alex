---

version: "3.1"

services:
  livy:
    image: scality/clueso-livy:test3
#    image: tobby48/spark-livy:0.3_2.1
    volumes:
      - /home/scality/alexenv/logs/livy:/apps/livy/logs
      - /home/scality/alexenv/conf/log4j.properties:/apps/livy/conf/log4j.properties
      - /home/scality/alexenv/conf/livy.conf:/apps/livy/conf/livy.conf
      - /home/scality/alexenv/conf/livy-env.sh:/apps/livy/conf/livy-env.sh
      - /home/scality/alexenv/spark_builds/spark-2.1.1-bin-spark-2.1.1_2.10:/apps/spark-2.1.1_2.10
      - /home/scality/alexenv/jars:/apps/spark-modules
    ports:
      - "8998:8998"
      - "4040:4040"
      - "5005:5005"
    depends_on:
      - kafka
      - spark-master
    networks:
      - frontend
    deploy:
      placement:
        constraints:
          - node.labels.io.zenko.type == livy

  spark-master:
    image: bde2020/spark-master:2.1.1-hadoop2.7
    hostname: spark-master
    depends_on:
      - kafka
    ports:
      - "8080:8080"
      - "7077:7077"
    environment:
      - INIT_DAEMON_STEP=setup_spark
    networks:
      - frontend

  spark-worker-1:
    image: bde2020/spark-worker:2.1.1-hadoop2.7
    depends_on:
      - spark-master
      - kafka
    ports:
      - "8081:8081"
    environment:
      - "SPARK_MASTER=spark://spark-master:7077"
    networks:
      - frontend

  spark-worker-2:
    image: bde2020/spark-worker:2.1.1-hadoop2.7
    depends_on:
      - spark-master
      - kafka
    ports:
      - "8082:8081"
    environment:
      - "SPARK_MASTER=spark://spark-master:7077"
    networks:
      - frontend

  kafka:
    image: spotify/kafka
    ports:
      - "9092:9092"
      - "2181:2181"
    environment:
      - "ADVERTISED_HOST=kafka"
      - "ADVERTISED_PORT=9092"
    networks:
      - frontend
# please remove assignment below before commit TODO 
    deploy:
      placement:
        constraints:
          - node.labels.io.zenko.type == livy

  s3-data:
    image: 127.0.0.1:5000/s3server
    ports:
      - "9991:9991"
    networks:
      - backend
    environment:
      S3DATAPATH: /data
      LISTEN_ADDR: 0.0.0.0
    volumes:
      - "s3-data:/data:rw"
    command: npm run start_dataserver
    deploy:
      placement:
        constraints:
          - node.labels.io.zenko.type == storage

  s3-metadata:
    image: 127.0.0.1:5000/s3server
    ports:
      - "9990:9990"
    networks:
      - backend
    environment:
      S3METADATAPATH: /metadata
      LISTEN_ADDR: 0.0.0.0
      RECORDLOG_ENABLED: "true"
    volumes:
      - 's3-metadata:/metadata:rw'
    command: npm run start_mdserver
    deploy:
      placement:
        constraints:
          - node.labels.io.zenko.type == storage

  s3-front:
    image: 127.0.0.1:5000/s3server
    ports:
      - "8000"
    networks:
      - backend
      - frontend-dmz
    environment:
      DATA_HOST: s3-data
      METADATA_HOST: s3-metadata
      REDIS_HOST: cache
      ENDPOINT: "${ENDPOINT:-zenko}"
      RECORDLOG_ENABLED: "true"
    secrets:
      - s3-credentials
    command: npm run start_s3server
    depends_on:
      - s3-data
      - s3-metadata
      - cache
    deploy:
      mode: replicated
      update_config:
        parallelism: 1
        delay: "10s"
        monitor: "5s"

  cache:
    image: redis:alpine
    ports:
      - "6379"
    networks:
      - backend

  lb:
    image: zenko/loadbalancer
    ports:
      - "80:80"
    environment:
      LISTEN_PORT: 80
      UPSTREAM_SERVER: "s3-front:8000"
    networks:
      - frontend
      - frontend-dmz
    depends_on:
      - s3-front
    deploy:
      mode: global
      update_config:
        parallelism: 1
        delay: "10s"
        monitor: "5s"

networks:
  backend:
  frontend:
  frontend-dmz:

volumes:
  s3-data:
  s3-metadata:

secrets:
  s3-credentials:
    file: ./secrets.txt
