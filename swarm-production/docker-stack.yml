---

version: "3.3"

services:

  livy:
    image: scality/clueso-livy:0.4.0
    ports:
      - "8998:8998"
      - "4040-4056:4040-4056"
      - "5005:5005"
    expose:
      - "10800"
      - "11211"
      - "47400-47500"
      - "47100"
    depends_on:
      - kafka
      - spark-master
      - graphite
    networks:
      - frontend
    environment:
      IGNITE_HOME: /ignite
    command: start
    deploy:
      placement:
        constraints:
          - node.labels.io.zenko.type == livy
    logging:
       options:
         max-size: "1g"
         max-file: "5"

  spark-master:
    image: scality/spark-master:hadoop2.8
    hostname: spark-master
    depends_on:
      - kafka
      - graphite
      - lb
    ports:
      - "8080:8080"
      - "7077:7077"
    environment:
      AWS_ACCESS_KEY_ID: accessKey1
      AWS_SECRET_KEY: verySecretKey1 
    networks:
      - frontend
    deploy:
      placement:
        constraints:
          - node.labels.io.zenko.type == livy

  spark-worker:
    image: scality/spark-worker:hadoop2.8
    depends_on:
      - spark-master
      - kafka
      - graphite
      - lb
    environment:
      SPARK_MASTER: spark://tasks.spark-master:7077
      CLUSTER_DNS: tasks.spark-worker
      INIT_REPLICATE: 1
    networks:
      - frontend
    deploy:
      replicas: 4
 
  graphite:
    image: scality/grafana_graphite
    ports:
      - '8000:80'
      - '8081:81'
      - '8125:8125/udp'
      - '8126:8126'
      - '2003:2003'
      - '2004:2004'
      - '7002:7002'
      - '3000:3000'
    networks:
      - frontend
    deploy:
      placement:
        constraints:
          - node.labels.io.zenko.type == livy

  kafka:
    image: spotify/kafka
    ports:
      - "9092:9092"
      - "2181:2181"
    environment:
      - "ADVERTISED_HOST=kafka"
      - "ADVERTISED_PORT=9092"
    networks:
      - frontend
# please remove assignment below before commit TODO 
    deploy:
      placement:
        constraints:
          - node.labels.io.zenko.type == livy

  s3-data:
    image: 127.0.0.1:5000/s3server
    ports:
      - "9991:9991"
    networks:
      - backend
    environment:
      S3DATAPATH: /data
      LISTEN_ADDR: 0.0.0.0
    volumes:
      - "s3-data:/data:rw"
    command: npm run start_dataserver
    deploy:
      placement:
        constraints:
          - node.labels.io.zenko.type == storage

  s3-metadata:
    image: 127.0.0.1:5000/s3server
    ports:
      - "9990:9990"
    networks:
      - backend
    environment:
      S3METADATAPATH: /metadata
      LISTEN_ADDR: 0.0.0.0
      RECORDLOG_ENABLED: "true"
    volumes:
      - 's3-metadata:/metadata:rw'
    command: npm run start_mdserver
    deploy:
      placement:
        constraints:
          - node.labels.io.zenko.type == storage

  s3-front:
    image: 127.0.0.1:5000/s3server
    ports:
      - "8000"
    networks:
      - backend
      - frontend
      - frontend-dmz
    environment:
      DATA_HOST: s3-data
      METADATA_HOST: s3-metadata
      REDIS_HOST: cache
      ENDPOINT: "${ENDPOINT:-zenko}"
      RECORDLOG_ENABLED: "true"
    secrets:
      - s3-credentials
    command: npm run start_s3server
    depends_on:
      - s3-data
      - s3-metadata
      - cache
    deploy:
      mode: replicated
      update_config:
        parallelism: 1
        delay: "10s"
        monitor: "5s"

  cache:
    image: redis:alpine
    ports:
      - "6379"
    networks:
      - backend

  lb:
    image: zenko/loadbalancer
    ports:
      - "80:80"
    environment:
      LISTEN_PORT: 80
      UPSTREAM_SERVER: "s3-front:8000"
    networks:
      - frontend
      - frontend-dmz
    depends_on:
      - s3-front
    deploy:
      mode: global
      update_config:
        parallelism: 1
        delay: "10s"
        monitor: "5s"

networks:
  backend:
  frontend:
  frontend-dmz:

volumes:
  s3-data:
  s3-metadata:

secrets:
  s3-credentials:
    file: ./secrets.txt
