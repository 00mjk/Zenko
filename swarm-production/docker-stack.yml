---

version: "3.3"

services:

  alluxio-master:
    image: scality/alluxio:latest
    ports:
      - "19998:19998"
      - "19999:19999"
    networks:
      - frontend
    environment:
      ALLUXIO_UNDERFS_ADDRESS: /underStorage
      ALLUXIO_MASTER_HOSTNAME: alluxio-master
    volumes:
      - /home/scality/alexenv/alluxio-working-dir/underStorage:/underStorage
    command: master
    deploy:
      placement:
        constraints:
          - node.labels.io.zenko.type == livy


#  alluxio-worker:
#    image: 127.0.0.1:5000/alluxio:latest
#    depends_on:
#      - alluxio-master
#    environment:
#      ALLUXIO_UNDERFS_ADDRESS: /underStorage
#      ALLUXIO_MASTER_HOSTNAME: alluxio-master
#      ALLUXIO_WORKER_MEMORY_SIZE: 8GB
#      ALLUXIO_WORKER_DATA_SERVER_DOMAIN_SOCKET_ADDRESS: /opt/domain/d
#    volumes:
#      - /home/scality/alexenv/alluxio-working-dir/underStorage:/underStorage
#      - /home/scality/alexenv/alluxio-working-dir/tmp/domain:/opt/domain
#      - alluxio-worker-vol:/dev/shm
#    ports:
#      - "30000"
#    command: worker
#    shm_size: 3g
#    networks:
#      - frontend
#    deploy:
#      resources:
#        mem_limit: 500000000
#      placement:
#        constraints:
#          - node.labels.io.zenko.type == livy

  livy:
    image: scality/clueso-livy:0.4.0-alluxio
    volumes:
      - /home/scality/alexenv/logs/livy:/apps/livy/logs
      - /home/scality/alexenv/conf/log4j.properties:/apps/livy/conf/log4j.properties
      - /home/scality/alexenv/conf/livy.conf:/apps/livy/conf/livy.conf
      - /home/scality/alexenv/conf/livy-env.sh:/apps/livy/conf/livy-env.sh
      - /home/scality/alexenv/spark_builds/spark-2.1.1-bin-spark-2.1.1_2.10:/apps/spark-2.1.1_2.10
      - /home/scality/alexenv/jars:/apps/spark-modules
    #  - /home/scality/alexenv/ignite-livy:/ignite
    #  - /home/scality/alexenv/spark_builds/spark-imgs/worker/spark-env.sh:/apps/spark/conf/spark-env.sh
    ports:
      - "8998:8998"
      - "4040-4056:4040-4056"
      - "5005:5005"
    expose:
      - "10800"
      - "11211"
      - "47400-47500"
      - "47100"
    depends_on:
      - kafka
      - spark-master
      - graphite
    networks:
      - frontend
    environment:
      IGNITE_HOME: /ignite
    deploy:
      placement:
        constraints:
          - node.labels.io.zenko.type == livy

  spark-master:
    #image: bde2020/spark-master:2.1.1-hadoop2.7
    image: scality/spark-master:hadoop2.8
    hostname: spark-master
    depends_on:
      - kafka
      - graphite
    ports:
      - "8080:8080"
      - "7077:7077"
    #environment:
    #  - INIT_DAEMON_STEP=setup_spark
    networks:
      - frontend
    deploy:
      placement:
        constraints:
          - node.labels.io.zenko.type == livy

  spark-worker:
    #image: bde2020/spark-worker:2.1.1-hadoop2.7
    #image: 127.0.0.1:5000/scality/spark-worker:hadoop2.8-ignite
    image: scality/spark-worker:hadoop2.8-alluxio
    #image: 127.0.0.1:5000/scality/spark-worker:hadoop2.8
    depends_on:
      - spark-master
      - kafka
      - graphite
      - alluxio-master
    #ports:
     # - "8081:8081"
     # - "30000"
    volumes:
      - alluxio-worker-vol:/dev/shm
    environment:
      SPARK_MASTER: spark://tasks.spark-master:7077
      CLUSTER_DNS: tasks.spark-worker
      INIT_REPLICATE: 1
      ALLUXIO_UNDERFS_ADDRESS: /underStorage
      ALLUXIO_MASTER_HOSTNAME: tasks.alluxio-master
    networks:
      - frontend
    deploy:
      replicas: 4
#      placement:
#        constraints:
#          - node.labels.io.zenko.type == livy
 
  graphite:
    image: scality/grafana_graphite
    ports:
      - '8000:80'
      - '8081:81'
      - '8125:8125/udp'
      - '8126:8126'
      - '2003:2003'
      - '2004:2004'
      - '7002:7002'
      - '3000:3000'
    networks:
      - frontend
    volumes:
      - /home/scality/alexenv/docker-grafana-graphite/data/whisper:/opt/graphite/storage/whisper
      - /home/scality/alexenv/docker-grafana-graphite/data/grafana:/opt/grafana/data
      - /home/scality/alexenv/docker-grafana-graphite/log/graphite:/opt/graphite/storage/log
    deploy:
      placement:
        constraints:
          - node.labels.io.zenko.type == livy

  kafka:
    image: spotify/kafka
    ports:
      - "9092:9092"
      - "2181:2181"
    environment:
      - "ADVERTISED_HOST=kafka"
      - "ADVERTISED_PORT=9092"
    networks:
      - frontend
# please remove assignment below before commit TODO 
    deploy:
      placement:
        constraints:
          - node.labels.io.zenko.type == livy

  s3-data:
    image: 127.0.0.1:5000/s3server
    ports:
      - "9991:9991"
    networks:
      - backend
    environment:
      S3DATAPATH: /data
      LISTEN_ADDR: 0.0.0.0
    volumes:
      - "s3-data:/data:rw"
    command: npm run start_dataserver
    deploy:
      placement:
        constraints:
          - node.labels.io.zenko.type == storage

  s3-metadata:
    image: 127.0.0.1:5000/s3server
    ports:
      - "9990:9990"
    networks:
      - backend
    environment:
      S3METADATAPATH: /metadata
      LISTEN_ADDR: 0.0.0.0
      RECORDLOG_ENABLED: "true"
    volumes:
      - 's3-metadata:/metadata:rw'
    command: npm run start_mdserver
    deploy:
      placement:
        constraints:
          - node.labels.io.zenko.type == storage

  s3-front:
    image: 127.0.0.1:5000/s3server
    ports:
      - "8000"
    networks:
      - backend
      - frontend
      - frontend-dmz
    environment:
      DATA_HOST: s3-data
      METADATA_HOST: s3-metadata
      REDIS_HOST: cache
      ENDPOINT: "${ENDPOINT:-zenko}"
      RECORDLOG_ENABLED: "true"
    secrets:
      - s3-credentials
    command: npm run start_s3server
    depends_on:
      - s3-data
      - s3-metadata
      - cache
    deploy:
      mode: replicated
      update_config:
        parallelism: 1
        delay: "10s"
        monitor: "5s"

  cache:
    image: redis:alpine
    ports:
      - "6379"
    networks:
      - backend

  lb:
    image: zenko/loadbalancer
    ports:
      - "80:80"
    environment:
      LISTEN_PORT: 80
      UPSTREAM_SERVER: "s3-front:8000"
    networks:
      - frontend
      - frontend-dmz
    depends_on:
      - s3-front
    deploy:
      mode: global
      update_config:
        parallelism: 1
        delay: "10s"
        monitor: "5s"

networks:
  backend:
  frontend:
  frontend-dmz:

volumes:
  s3-data:
  s3-metadata:

  alluxio-worker-vol:
    driver_opts:
      type: tmpfs
      device: tmpfs

secrets:
  s3-credentials:
    file: ./secrets.txt
