version: "3.4"

services:
  s3-data:
    image: zenko/cloudserver:pensieve-2
    ports:
      - "9992"
    networks:
      - backend
    environment:
      S3DATAPATH: /data
      LISTEN_ADDR: 0.0.0.0
    volumes:
      - "s3-data:/data:rw"
    command: npm run start_dataserver
    deploy:
      placement:
        constraints:
          - node.labels.io.zenko.type == storage

  s3-metadata:
    image: zenko/cloudserver:pensieve-2
    ports:
      - "9993"
    networks:
      - backend
    environment:
      S3METADATAPATH: /metadata
      LISTEN_ADDR: 0.0.0.0
      RECORDLOG_ENABLED: "true"
    volumes:
      - 's3-metadata:/metadata:rw'
    command: npm run start_mdserver
    deploy:
      placement:
        constraints:
          - node.labels.io.zenko.type == storage

  s3-front:
    image: zenko/cloudserver:pensieve-2
    ports:
      - "8001"
    networks:
      backend:
        aliases:
          - zenko-cloudserver-replicator
      frontend-dmz:
    environment:
      DATA_HOST: s3-data
      METADATA_HOST: s3-metadata
      REDIS_HOST: cache
      ENDPOINT: "${ENDPOINT:-zenko}"
      REMOTE_MANAGEMENT_DISABLE: "${REMOTE_MANAGEMENT_DISABLE:-0}"
    secrets:
      - s3-credentials
    command: npm run start_s3server
    depends_on:
      - s3-data
      - s3-metadata
      - cache
    deploy:
      mode: replicated
      update_config:
        parallelism: 1
        delay: "10s"
        monitor: "5s"

  cache:
    image: redis:alpine
    ports:
      - "6379"
    networks:
      - backend

  lb:
    image: zenko/loadbalancer
    ports:
      - "80:80"
    environment:
      LISTEN_PORT: 80
      UPSTREAM_SERVER: "s3-front:8001"
    networks:
      - frontend
      - frontend-dmz
    depends_on:
      - s3-front
    deploy:
      mode: global
      update_config:
        parallelism: 1
        delay: "10s"
        monitor: "5s"

  livy:
    image: scality/clueso-livy:pensieve
    hostname: livy
    ports:
      - "8998:8998"
      # so that each spawned session can have an app ui, open range
      - "4040-4049:4040-4049"
    depends_on:
      - spark-master
    networks:
      - backend
      # need so can contact lb to get parquet files on search
      - frontend-dmz

  spark-master:
    image: scality/clueso-spark-master:pensieve
    hostname: spark-master
    depends_on:
      - queue
      - graphite
      - lb
    ports:
      # master ui:
      - "8080:8080"
      # ingestion pipeline app ui:
      - "4050:4050"
      # landing populator app ui:
      - "4051:4051"
      # storage info tool app ui
      - "4052:4052"
      # compactor tool app ui
      - "4053:4053"
    volumes:
      - "heapdumps:/clueso/heapdumps:rw"
    secrets:
      - s3-credentials
    networks:
      - backend
      # need so can contact lb to create METADATA bucket
      - frontend-dmz

  spark-worker:
    image: scality/clueso-spark-worker:pensieve
    depends_on:
      - spark-master
    environment:
      SPARK_MASTER_HOST: spark://spark-master:7077
      CLUSTER_DNS: spark-worker
      INIT_REPLICATE: 1
    networks:
      - backend
      # need so can contact lb to get parquet files on search
      - frontend-dmz
    deploy:
      replicas: 1

  graphite:
    image: scality/clueso-grafana-graphite
    depends_on:
      - spark-master
    ports:
      - '8005:80'
      - '8081:81'
      - '3000:3000'
    networks:
      - backend
    volumes:
      - "grafana-data:/opt/grafana/data:rw"
    deploy:
      placement:
        constraints:
          - node.labels.io.zenko.type == storage

  queue:
    image: 'wurstmeister/kafka:1.0.0'
    environment:
      KAFKA_ADVERTISED_PORT: 9092
      KAFKA_ADVERTISED_HOST_NAME: queue
      KAFKA_CREATE_TOPICS: 'backbeat:1:1'
      KAFKA_ZOOKEEPER_CONNECT: 'quorum:2181'
      KAFKA_HEAP_OPTS: '-Xmx512M'
      KAFKA_LOG_DIRS: /kafka/kafka-logs
    ports:
      - 9092
    networks:
      - backend
    volumes:
      - "queue-journal:/kafka:rw"
    depends_on:
      - quorum
    deploy:
      mode: replicated
      replicas: 1
      placement:
        constraints:
          - node.labels.io.zenko.type == storage

  quorum:
    image: 'zookeeper:3.4.11'
    ports:
      - 2181
    networks:
      - backend
    volumes:
      - "quorum-data:/data:rw"
      - "quorum-datalog:/datalog:rw"
    deploy:
      mode: replicated
      replicas: 1
      placement:
        constraints:
          - node.labels.io.zenko.type == storage

  backbeat-producer:
    image: 'zenko/backbeat:pensieve-3'
    command: npm run queue_populator
    environment:
      ZOOKEEPER_AUTO_CREATE_NAMESPACE: 1
      ZOOKEEPER_CONNECTION_STRING: 'quorum:2181'
      KAFKA_HOSTS: 'queue:9092'
      QUEUE_POPULATOR_DMD_HOST: 's3-metadata'
      QUEUE_POPULATOR_DMD_PORT: 9993
    networks:
      - backend
    depends_on:
      - quorum
      - queue
      - s3-metadata
    deploy:
      mode: replicated
      replicas: 1

  backbeat-consumer:
    image: 'zenko/backbeat:pensieve-3'
    command: npm run queue_processor
    environment:
      ZOOKEEPER_AUTO_CREATE_NAMESPACE: 1
      ZOOKEEPER_CONNECTION_STRING: 'quorum:2181'
      KAFKA_HOSTS: 'queue:9092'
      EXTENSIONS_REPLICATION_SOURCE_AUTH_TYPE: 'service'
      EXTENSIONS_REPLICATION_SOURCE_AUTH_ACCOUNT: 'service-replication'
      EXTENSIONS_REPLICATION_SOURCE_S3_HOST: 'zenko-cloudserver-replicator'
      EXTENSIONS_REPLICATION_SOURCE_S3_PORT: 8001
      EXTENSIONS_REPLICATION_DEST_AUTH_TYPE: 'service'
      EXTENSIONS_REPLICATION_DEST_AUTH_ACCOUNT: 'service-replication'
      EXTENSIONS_REPLICATION_DEST_BOOTSTRAPLIST: 'zenko-cloudserver-replicator:8001'
      QUEUE_POPULATOR_DMD_HOST: 's3-metadata'
      QUEUE_POPULATOR_DMD_PORT: 9993
    networks:
      - backend
    depends_on:
      - quorum
      - queue
      - s3-metadata
      - s3-front
    deploy:
      mode: replicated
      replicas: 1

networks:
  backend:
  frontend:
  frontend-dmz:

volumes:
  s3-data:
  s3-metadata:
  grafana-data:
  queue-journal:
  quorum-data:
  quorum-datalog:
  heapdumps:

secrets:
  s3-credentials:
    file: ./secrets.txt
